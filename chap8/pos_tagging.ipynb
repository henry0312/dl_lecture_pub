{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX TITAN X\n"
     ]
    }
   ],
   "source": [
    "import theano.sandbox.cuda\n",
    "theano.sandbox.cuda.use(\"gpu0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import numpy\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scan\n",
    "\n",
    "Theano ではループのために For 文ではなく、Scan というものを使います　　\n",
    "少しややこしいので、簡単な例を"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  2.  3.  4.  5.]\n"
     ]
    }
   ],
   "source": [
    "##Suppose you have a sequence [1, 2, 3, 4, 5] let's define identity function with scan\n",
    "x = T.fvector(\"x\")\n",
    "\n",
    "def step(x):\n",
    "    return x\n",
    "\n",
    "h, _ = theano.scan(\n",
    "                       fn=step,\n",
    "                       sequences=x, \n",
    "                       outputs_info=None # 初期値\n",
    "                    )\n",
    "\n",
    "f = theano.function([x], h)\n",
    "\n",
    "print( f(numpy.array([1, 2, 3, 4, 5]).astype(\"float32\")) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1.   3.   6.  10.  15.]\n"
     ]
    }
   ],
   "source": [
    "##Next we define accumulation function\n",
    "x = T.fvector(\"x\")\n",
    "\n",
    "def step(x, h_tm1):\n",
    "    return x + h_tm1\n",
    "\n",
    "h, _ = theano.scan(\n",
    "                       fn=step,\n",
    "                       sequences=x, \n",
    "                       outputs_info=0.0, #Initial value for h\n",
    "                       #go_backwards=True #you might use it for bi-directional RNNs\n",
    "                    )\n",
    "\n",
    "f = theano.function([x], h)\n",
    "\n",
    "print( f(numpy.array([1, 2, 3, 4, 5]).astype(\"float32\")) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.   2.   3.   4.   5.]\n",
      " [  2.   4.   6.   8.  10.]\n",
      " [  3.   6.   9.  12.  15.]]\n"
     ]
    }
   ],
   "source": [
    "## Let's do the same thing with matrix, accumulation over column\n",
    "x = T.fmatrix(\"x\")\n",
    "\n",
    "def step(x, h_tm1):\n",
    "    return x + h_tm1\n",
    "\n",
    "h, _ = theano.scan(\n",
    "                       fn=step,\n",
    "                       sequences=x, \n",
    "                       outputs_info=numpy.array([0., 0., 0., 0., 0.]) #Initial value for h, it's better to use T.alloc().\n",
    "                    )\n",
    "\n",
    "f = theano.function([x], h)\n",
    "\n",
    "print( f(numpy.array([[1, 2, 3, 4, 5], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5]]).astype(\"float32\")) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.   6.   9.  12.  15.]\n",
      " [  3.   6.   9.  12.  15.]\n",
      " [  3.   6.   9.  12.  15.]]\n"
     ]
    }
   ],
   "source": [
    "## Advanced :: take previous inputs\n",
    "x = T.fmatrix(\"x\")\n",
    "\n",
    "def step(x, h_tm1, h_tm2):\n",
    "    return x + h_tm1 + h_tm2\n",
    "\n",
    "h, _ = theano.scan(\n",
    "                       fn=step,\n",
    "                       sequences=[ dict(input= x, taps = [0, -1, -2])],\n",
    "                       outputs_info=None #Initial value for h\n",
    "                    )\n",
    "\n",
    "f = theano.function([x], h)\n",
    "\n",
    "print(\n",
    "    f(numpy.array([[1, 2, 3, 4, 5], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5]]).astype(\"float32\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [宿題] POS Tagging\n",
    "\n",
    "文が与えられた時、その品詞を予測する RNN を学習します。\n",
    "\n",
    "word2index は単語をIDに変換する辞書、tag2index は品詞をIDに変換する辞書です。  \n",
    "train_data, dev_data には文と品詞タグのペアが入っています。  \n",
    "文の長さと品詞タグの長さは必ず同じです。\n",
    "\n",
    "encode_dataset を使うと単語と品詞をIDに変換することができます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "import numpy\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def load_data(file_path):\n",
    "    dataset = []\n",
    "    vocab, tag = set(), set()\n",
    "    for line in open(file_path):\n",
    "        # \"a pen ||| \" => [['a', 'pen'], ['DT', 'NN']]\n",
    "        instance = [ l.strip().split() for l in line.split('|||') ]\n",
    "        vocab.update(instance[0])\n",
    "        tag.update(instance[1])\n",
    "        dataset.append(instance)\n",
    "    return dataset, vocab, tag\n",
    "\n",
    "def encode_dataset(dataset, word2index, tag2index):\n",
    "    X, y = [], []\n",
    "    vocab = set(word2index.keys())\n",
    "    for sentence, tags in dataset:\n",
    "        X.append([ word2index[word] if word in vocab else word2index['<unk>'] for word in sentence])\n",
    "        y.append([ tag2index[tag] for tag in tags])\n",
    "    return X, y\n",
    "\n",
    "train_data, train_vocab, train_tags = load_data('train.unk')\n",
    "special_words = set(['<unk>']) # 未知の単語に使う\n",
    "\n",
    "# {'a': 1, 'pen': 1}\n",
    "word2index = dict(map(lambda x: (x[1], x[0]), enumerate(train_vocab | special_words)))\n",
    "tag2index  = dict(map(lambda x: (x[1], x[0]), enumerate(train_tags)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_size = len(train_data)\n",
    "train_data, dev_data = train_data[:train_size//10 * 8], train_data[train_size//10 * 8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In IN\n",
      "an DT\n",
      "Oct. NNP\n",
      "19 CD\n",
      "review NN\n",
      "of IN\n",
      "`` ``\n",
      "The DT\n",
      "Misanthrope NN\n",
      "'' ''\n",
      "at IN\n",
      "Chicago NNP\n",
      "'s POS\n",
      "Goodman NNP\n",
      "Theatre NNP\n",
      "`` ``\n",
      "Revitalized VBN\n",
      "Classics NNS\n",
      "Take VBP\n",
      "the DT\n",
      "Stage NN\n",
      "in IN\n",
      "Windy NNP\n",
      "City NNP\n",
      ", ,\n",
      "'' ''\n",
      "Leisure NN\n",
      "& CC\n",
      "Arts NNS\n",
      ", ,\n",
      "the DT\n",
      "role NN\n",
      "of IN\n",
      "Celimene NNP\n",
      ", ,\n",
      "played VBN\n",
      "by IN\n",
      "Kim NNP\n",
      "Cattrall NNP\n",
      ", ,\n",
      "was VBD\n",
      "mistakenly RB\n",
      "attributed VBN\n",
      "to TO\n",
      "Christina NNP\n",
      "Haag NNP\n",
      ". .\n"
     ]
    }
   ],
   "source": [
    "# train_data[0] = train.unk の1行目を表示\n",
    "for word, tag in zip(train_data[0][0], train_data[0][1]):\n",
    "    print(word, tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のセルを完成させて提出してください　　\n",
    "\n",
    "今回の入力は単語のID列（ベクトル x）と品詞のID列 (ベクトル y)です。  \n",
    "Projection レイヤーを使って、単語をベクトルに変換します。  \n",
    "その後、RNN に入力し、その出力値をSotfmax関数を使って確率分布に変換します。  \n",
    "予測は画像の時とおなじく、最大の確率を持つクラスを予測とします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH::   1, Validatioon Cost:: 2.674, Validation F1:: 0.323\n",
      "EPOCH::   2, Validatioon Cost:: 2.285, Validation F1:: 0.408\n",
      "EPOCH::   3, Validatioon Cost:: 2.043, Validation F1:: 0.464\n",
      "EPOCH::   4, Validatioon Cost:: 1.874, Validation F1:: 0.496\n",
      "EPOCH::   5, Validatioon Cost:: 1.759, Validation F1:: 0.529\n",
      "EPOCH::   6, Validatioon Cost:: 1.668, Validation F1:: 0.543\n",
      "EPOCH::   7, Validatioon Cost:: 1.594, Validation F1:: 0.567\n",
      "EPOCH::   8, Validatioon Cost:: 1.523, Validation F1:: 0.576\n",
      "EPOCH::   9, Validatioon Cost:: 1.481, Validation F1:: 0.589\n",
      "EPOCH::  10, Validatioon Cost:: 1.432, Validation F1:: 0.611\n",
      "EPOCH::  11, Validatioon Cost:: 1.387, Validation F1:: 0.615\n",
      "EPOCH::  12, Validatioon Cost:: 1.352, Validation F1:: 0.627\n",
      "EPOCH::  13, Validatioon Cost:: 1.321, Validation F1:: 0.650\n",
      "EPOCH::  14, Validatioon Cost:: 1.291, Validation F1:: 0.653\n",
      "EPOCH::  15, Validatioon Cost:: 1.245, Validation F1:: 0.664\n",
      "EPOCH::  16, Validatioon Cost:: 1.218, Validation F1:: 0.671\n",
      "EPOCH::  17, Validatioon Cost:: 1.204, Validation F1:: 0.684\n",
      "EPOCH::  18, Validatioon Cost:: 1.170, Validation F1:: 0.692\n",
      "EPOCH::  19, Validatioon Cost:: 1.151, Validation F1:: 0.697\n",
      "EPOCH::  20, Validatioon Cost:: 1.133, Validation F1:: 0.703\n",
      "EPOCH::  21, Validatioon Cost:: 1.112, Validation F1:: 0.711\n",
      "EPOCH::  22, Validatioon Cost:: 1.099, Validation F1:: 0.720\n",
      "EPOCH::  23, Validatioon Cost:: 1.080, Validation F1:: 0.719\n",
      "EPOCH::  24, Validatioon Cost:: 1.063, Validation F1:: 0.730\n",
      "EPOCH::  25, Validatioon Cost:: 1.051, Validation F1:: 0.729\n",
      "EPOCH::  26, Validatioon Cost:: 1.036, Validation F1:: 0.739\n",
      "EPOCH::  27, Validatioon Cost:: 1.016, Validation F1:: 0.740\n",
      "EPOCH::  28, Validatioon Cost:: 1.016, Validation F1:: 0.739\n",
      "EPOCH::  29, Validatioon Cost:: 1.006, Validation F1:: 0.750\n",
      "EPOCH::  30, Validatioon Cost:: 0.994, Validation F1:: 0.753\n",
      "EPOCH::  31, Validatioon Cost:: 0.981, Validation F1:: 0.751\n",
      "EPOCH::  32, Validatioon Cost:: 0.976, Validation F1:: 0.757\n",
      "EPOCH::  33, Validatioon Cost:: 0.973, Validation F1:: 0.756\n",
      "EPOCH::  34, Validatioon Cost:: 0.965, Validation F1:: 0.761\n",
      "EPOCH::  35, Validatioon Cost:: 0.960, Validation F1:: 0.763\n",
      "EPOCH::  36, Validatioon Cost:: 0.950, Validation F1:: 0.767\n",
      "EPOCH::  37, Validatioon Cost:: 0.952, Validation F1:: 0.772\n",
      "EPOCH::  38, Validatioon Cost:: 0.952, Validation F1:: 0.771\n",
      "EPOCH::  39, Validatioon Cost:: 0.951, Validation F1:: 0.769\n",
      "EPOCH::  40, Validatioon Cost:: 0.938, Validation F1:: 0.777\n",
      "EPOCH::  41, Validatioon Cost:: 0.937, Validation F1:: 0.778\n",
      "EPOCH::  42, Validatioon Cost:: 0.939, Validation F1:: 0.779\n",
      "EPOCH::  43, Validatioon Cost:: 0.932, Validation F1:: 0.778\n",
      "EPOCH::  44, Validatioon Cost:: 0.932, Validation F1:: 0.781\n",
      "EPOCH::  45, Validatioon Cost:: 0.934, Validation F1:: 0.786\n",
      "EPOCH::  46, Validatioon Cost:: 0.936, Validation F1:: 0.782\n",
      "EPOCH::  47, Validatioon Cost:: 0.932, Validation F1:: 0.789\n",
      "EPOCH::  48, Validatioon Cost:: 0.928, Validation F1:: 0.788\n",
      "EPOCH::  49, Validatioon Cost:: 0.933, Validation F1:: 0.790\n",
      "EPOCH::  50, Validatioon Cost:: 0.927, Validation F1:: 0.789\n",
      "EPOCH::  51, Validatioon Cost:: 0.930, Validation F1:: 0.792\n",
      "EPOCH::  52, Validatioon Cost:: 0.930, Validation F1:: 0.792\n",
      "EPOCH::  53, Validatioon Cost:: 0.928, Validation F1:: 0.792\n",
      "EPOCH::  54, Validatioon Cost:: 0.932, Validation F1:: 0.794\n",
      "EPOCH::  55, Validatioon Cost:: 0.927, Validation F1:: 0.794\n",
      "EPOCH::  56, Validatioon Cost:: 0.927, Validation F1:: 0.795\n",
      "EPOCH::  57, Validatioon Cost:: 0.947, Validation F1:: 0.796\n",
      "EPOCH::  58, Validatioon Cost:: 0.936, Validation F1:: 0.796\n",
      "EPOCH::  59, Validatioon Cost:: 0.931, Validation F1:: 0.799\n",
      "EPOCH::  60, Validatioon Cost:: 0.941, Validation F1:: 0.798\n",
      "EPOCH::  61, Validatioon Cost:: 0.936, Validation F1:: 0.797\n",
      "EPOCH::  62, Validatioon Cost:: 0.944, Validation F1:: 0.797\n",
      "EPOCH::  63, Validatioon Cost:: 0.936, Validation F1:: 0.798\n",
      "EPOCH::  64, Validatioon Cost:: 0.942, Validation F1:: 0.798\n",
      "EPOCH::  65, Validatioon Cost:: 0.939, Validation F1:: 0.799\n",
      "EPOCH::  66, Validatioon Cost:: 0.944, Validation F1:: 0.801\n",
      "EPOCH::  67, Validatioon Cost:: 0.944, Validation F1:: 0.802\n",
      "EPOCH::  68, Validatioon Cost:: 0.942, Validation F1:: 0.801\n",
      "EPOCH::  69, Validatioon Cost:: 0.949, Validation F1:: 0.802\n",
      "EPOCH::  70, Validatioon Cost:: 0.948, Validation F1:: 0.803\n",
      "EPOCH::  71, Validatioon Cost:: 0.960, Validation F1:: 0.801\n",
      "EPOCH::  72, Validatioon Cost:: 0.960, Validation F1:: 0.802\n",
      "EPOCH::  73, Validatioon Cost:: 0.955, Validation F1:: 0.804\n",
      "EPOCH::  74, Validatioon Cost:: 0.957, Validation F1:: 0.803\n",
      "EPOCH::  75, Validatioon Cost:: 0.960, Validation F1:: 0.803\n",
      "EPOCH::  76, Validatioon Cost:: 0.965, Validation F1:: 0.802\n",
      "EPOCH::  77, Validatioon Cost:: 0.966, Validation F1:: 0.803\n",
      "EPOCH::  78, Validatioon Cost:: 0.958, Validation F1:: 0.805\n",
      "EPOCH::  79, Validatioon Cost:: 0.969, Validation F1:: 0.804\n",
      "EPOCH::  80, Validatioon Cost:: 0.975, Validation F1:: 0.802\n",
      "EPOCH::  81, Validatioon Cost:: 0.967, Validation F1:: 0.805\n",
      "EPOCH::  82, Validatioon Cost:: 0.966, Validation F1:: 0.805\n",
      "EPOCH::  83, Validatioon Cost:: 0.977, Validation F1:: 0.803\n",
      "EPOCH::  84, Validatioon Cost:: 0.971, Validation F1:: 0.805\n",
      "EPOCH::  85, Validatioon Cost:: 0.975, Validation F1:: 0.806\n",
      "EPOCH::  86, Validatioon Cost:: 0.985, Validation F1:: 0.805\n",
      "EPOCH::  87, Validatioon Cost:: 0.983, Validation F1:: 0.806\n",
      "EPOCH::  88, Validatioon Cost:: 0.985, Validation F1:: 0.805\n",
      "EPOCH::  89, Validatioon Cost:: 0.981, Validation F1:: 0.806\n",
      "EPOCH::  90, Validatioon Cost:: 0.989, Validation F1:: 0.807\n",
      "EPOCH::  91, Validatioon Cost:: 0.994, Validation F1:: 0.805\n",
      "EPOCH::  92, Validatioon Cost:: 0.997, Validation F1:: 0.806\n",
      "EPOCH::  93, Validatioon Cost:: 0.989, Validation F1:: 0.805\n",
      "EPOCH::  94, Validatioon Cost:: 0.991, Validation F1:: 0.806\n",
      "EPOCH::  95, Validatioon Cost:: 0.996, Validation F1:: 0.806\n",
      "EPOCH::  96, Validatioon Cost:: 0.997, Validation F1:: 0.807\n",
      "EPOCH::  97, Validatioon Cost:: 0.999, Validation F1:: 0.806\n",
      "EPOCH::  98, Validatioon Cost:: 1.003, Validation F1:: 0.808\n",
      "EPOCH::  99, Validatioon Cost:: 1.000, Validation F1:: 0.808\n",
      "EPOCH:: 100, Validatioon Cost:: 1.008, Validation F1:: 0.806\n"
     ]
    }
   ],
   "source": [
    "train_size = len(train_data)\n",
    "train_data, dev_data = train_data[:train_size//10 * 8], train_data[train_size//10 * 8:]\n",
    "\n",
    "train_X, train_y = encode_dataset(train_data, word2index, tag2index)\n",
    "dev_X  , dev_y   = encode_dataset(dev_data,   word2index, tag2index)\n",
    "\n",
    "rng = numpy.random.RandomState(42)\n",
    "trng = RandomStreams(42)\n",
    "\n",
    "def sharedX(X, dtype=\"float32\"):\n",
    "    return theano.shared(numpy.asarray(X, dtype=dtype))\n",
    "\n",
    "\n",
    "class Activation:\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "        self.params = []\n",
    "\n",
    "    def fprop(self, x):\n",
    "        return self.func(x)\n",
    "\n",
    "\n",
    "class Projection:\n",
    "    def __init__(self, in_dim, out_dim, scale):\n",
    "        self.W = sharedX(rng.randn(in_dim, out_dim) * scale)\n",
    "        self.params = [ self.W ]\n",
    "\n",
    "    def fprop(self, x):\n",
    "        h = self.W[x]\n",
    "        return h\n",
    "    \n",
    "    \n",
    "class Linear:\n",
    "    def __init__(self, in_dim, out_dim, scale):\n",
    "        self.W = sharedX(rng.randn(in_dim, out_dim) * scale)\n",
    "        self.b = sharedX(rng.randn(out_dim,) * scale)\n",
    "        self.params = [ self.W, self.b ]\n",
    "\n",
    "    def fprop(self, x):\n",
    "        h = T.dot(x, self.W)+self.b\n",
    "        return h\n",
    "\n",
    "    \n",
    "class RNN:\n",
    "    def __init__(self, in_dim, out_dim, scale):\n",
    "        self.scale = scale\n",
    "        self.hid_dim = hid_dim\n",
    "\n",
    "        ## 重みの次元を決める。\n",
    "        self.Wx = sharedX(rng.randn(in_dim, out_dim) * scale)\n",
    "        self.Wh = sharedX(rng.randn(out_dim, out_dim) * scale)\n",
    "        self.bh = sharedX(rng.randn(out_dim,) * scale)\n",
    "        ## Initial State をどのように初期化するか\n",
    "        self.h0 = sharedX(numpy.zeros(out_dim,))\n",
    "\n",
    "        self.output_info = [ self.h0 ]\n",
    "        self.params = [ self.Wx, self.Wh, self.bh, self.h0 ]\n",
    "\n",
    "    def fprop(self, x):\n",
    "        def step(u_t, h_tm1):\n",
    "            h = T.tanh(T.dot(u_t, self.Wx)  + T.dot(h_tm1, self.Wh) + self.bh)\n",
    "            return h\n",
    "        \n",
    "        ## Scan の方法を考える \n",
    "        h, _ = theano.scan(\n",
    "            fn=step,\n",
    "            sequences=x,\n",
    "            outputs_info=self.h0\n",
    "        )\n",
    "        return h\n",
    "    \n",
    "\n",
    "def sgd(cost, params, lr):\n",
    "    gparams = T.grad(cost, params)\n",
    "    updates = OrderedDict()\n",
    "    for param, gparam in zip(params, gparams):\n",
    "        ## Advanced Gradient Glip を実装する　（必須ではない）\n",
    "        updates[param] = param - lr * gparam\n",
    "    return updates\n",
    "\n",
    "\n",
    "def prop(layers, x):\n",
    "    for i, layer in enumerate(layers):\n",
    "        if i == 0:\n",
    "            layer_out = layer.fprop(x)\n",
    "        else:\n",
    "            layer_out = layer.fprop(layer_out)\n",
    "    return layer_out\n",
    "\n",
    "\n",
    "def get_params(layers):\n",
    "    params = []\n",
    "    for layer in layers:\n",
    "        params += layer.params\n",
    "    return params\n",
    "\n",
    "\n",
    "### build Model + Train\n",
    "vocab_size = len(word2index)\n",
    "hid_dim    = 100\n",
    "out_dim    = len(tag2index)\n",
    "\n",
    "x, t = T.lvector(\"x\"), T.lvector(\"t\")\n",
    "\n",
    "layers = [\n",
    "    Projection(vocab_size, hid_dim, scale=0.09), # scale?\n",
    "    RNN(hid_dim, out_dim, scale=0.5), # scale?\n",
    "    Linear(out_dim, out_dim, scale=0.5), # scale?\n",
    "    Activation(func=T.nnet.softmax)\n",
    "]\n",
    "\n",
    "prob = prop(layers, x)\n",
    "cost = -T.mean(T.log(prob)[T.arange(t.shape[0]), t]) # WRITEME\n",
    "pred = T.argmax(prob, axis=1) # WRITEME\n",
    "\n",
    "## Collect Parameters\n",
    "params = get_params(layers) \n",
    "\n",
    "## Define update graph\n",
    "updates = sgd(cost, params, lr=numpy.float32(0.01)) \n",
    "\n",
    "## Compile Function\n",
    "train = theano.function([x,t], cost, updates=updates)\n",
    "valid = theano.function([x,t], [cost, pred])\n",
    "test  = theano.function([x], pred)\n",
    "\n",
    "epochs = 100\n",
    "## Train\n",
    "for epoch in range(epochs):\n",
    "    train_X, train_y = shuffle(train_X, train_y)  # Shuffle Samples !!\n",
    "    for i, (instance_x, instance_y) in enumerate(zip(train_X, train_y)):\n",
    "        cost = train(instance_x, instance_y)\n",
    "        #if i % 1000 == 0:\n",
    "            #print(\"EPOCH:: %i, Iteration %i, cost: %.3f\"%(epoch+1, i, cost))\n",
    "    \n",
    "    dev_true, dev_pred = [], []\n",
    "    costs = []\n",
    "    for i, (instance_x, instance_y) in enumerate(zip(dev_X, dev_y)):\n",
    "        cost, pred = valid(instance_x, instance_y)\n",
    "        dev_pred += list(pred) # 予測結果はベクトル\n",
    "        dev_true += instance_y\n",
    "        costs.append(cost)\n",
    "\n",
    "    if True:\n",
    "    #if ((epoch+1) % 10 == 0) or (epoch == 0):\n",
    "        print(\"EPOCH:: {:3d}, Validatioon Cost:: {:.3f}, Validation F1:: {:.3f}\".format(\n",
    "                        epoch+1,\n",
    "                        numpy.mean(costs),\n",
    "                        f1_score(dev_true, dev_pred, average=\"micro\")\n",
    "                    ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
