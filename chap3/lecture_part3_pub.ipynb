{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 第3回 演習課題"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題1．単純パーセプトロンの実装と学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.層をLayerクラスとして定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self,in_dim,out_dim,function):\n",
    "        self.W = np.zeros((in_dim,out_dim))\n",
    "        self.b = np.zeros(out_dim)\n",
    "        self.function = function\n",
    "\n",
    "    #forward propagation\n",
    "    def fprop(self,x):\n",
    "        u = x.dot(self.W) + self.b\n",
    "        z = self.function(u)\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.ステップ関数\n",
    "\n",
    "ヒント：ステップ関数\n",
    "\n",
    "* $u\\geq0$のとき，$f(u)=+1$\n",
    "* $u<0$のとき，$f(u)=-1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def step(x):\n",
    "    y = np.sign(x)\n",
    "    y[y==0] = 1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.データセットの設定とレイヤーインスタンス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#OR\n",
    "train_X = np.array([[0,1],[1,0],[0,0],[1,1]])\n",
    "train_y = np.array([[1],[1],[-1],[1]])\n",
    "test_X,test_y = train_X,train_y\n",
    "\n",
    "layer = Layer(2,1,step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.train関数とtest関数\n",
    "\n",
    "ヒント：パーセプトロン学習則\n",
    "\n",
    "$y_n\\neq d_n$のとき\n",
    "* $w^{(t+1)}=w^{(t)}+\\epsilon x_nd_n$　\n",
    "* $b^{(t+1)}=b^{(t)}+\\epsilon d_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(x,d,eps=1):\n",
    "    #forward propagation\n",
    "    y = layer.fprop(x)\n",
    "\n",
    "    #update parameters\n",
    "    if y * d != 1:\n",
    "        layer.W = layer.W + eps*d*x.T\n",
    "        layer.b = layer.b + eps*d\n",
    "\n",
    "def test(x):\n",
    "    y = layer.fprop(x)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.パラメータの更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.]\n",
      " [ 1.]\n",
      " [-1.]\n",
      " [ 1.]]\n"
     ]
    }
   ],
   "source": [
    "#epoch\n",
    "for epoch in range(10):\n",
    "    #online learning\n",
    "    for x,y in zip(train_X,train_y):\n",
    "        train(x[np.newaxis,:],y[np.newaxis,:],eps=1)\n",
    "pred_y = test(test_X)\n",
    "print(pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題2．活性化関数とその微分の実装"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.シグモイド関数とその微分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "def diff_sigmoid(x):\n",
    "    v = sigmoid(x)\n",
    "    return v * (1.0 - v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "２.ソフトマックス関数とその微分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    v = np.exp(x)\n",
    "    return v / np.sum(v, axis=1)[:, np.newaxis]\n",
    "def diff_softmax(x):\n",
    "    v = softmax(x)\n",
    "    return v * (np.ones(x.shape) - v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.tanh関数とその微分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tanh(x):\n",
    "    return np.tanh(x)\n",
    "def diff_tanh(x):\n",
    "    v = tahnh(x)\n",
    "    return 1 - v*v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 課題3．多層パーセプトロンの実装と学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "1.Layerクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self,in_dim,out_dim,function,diff_function):\n",
    "        #Xavier\n",
    "        self.W = np.random.uniform(\n",
    "                                    low=-np.sqrt(6./(in_dim+out_dim)), \n",
    "                                    high=np.sqrt(6./(in_dim+out_dim)), \n",
    "                                    size=(in_dim, out_dim))\n",
    "        self.b = np.zeros(out_dim)\n",
    "        self.function = function\n",
    "        \n",
    "        self.diff_function = diff_function\n",
    "        self.u     = None\n",
    "        self.delta = None\n",
    "\n",
    "    #forward propagation\n",
    "    def fprop(self,x):\n",
    "        self.u = np.dot(x, self.W) + self.b\n",
    "        z = self.function(self.u)\n",
    "        return z\n",
    "\n",
    "    #back propagation\n",
    "    def bprop(self,delta,W):\n",
    "        self.delta = self.diff_function(self.u) * delta.dot(W.T)\n",
    "        return self.delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.ネットワーク全体の順伝播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fprops(layers, x):\n",
    "    z = x\n",
    "    for layer in layers:\n",
    "        z = layer.fprop(z)    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.ネットワーク全体の誤差逆伝播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bprops(layers, delta):\n",
    "    for i,layer in enumerate(layers[::-1]):\n",
    "        if i == 0:\n",
    "            layer.delta = delta\n",
    "        else:\n",
    "            delta = layer.bprop(delta, _W)\n",
    "        _W = layer.W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.データセットの設定とネットワークの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#XOR\n",
    "train_X = np.array([[0,1],[1,0],[0,0],[1,1]])\n",
    "train_y = np.array([[1],[1],[0],[0]])\n",
    "test_X,test_y = train_X,train_y\n",
    "\n",
    "layers = [Layer(2,3,sigmoid,diff_sigmoid),\n",
    "          Layer(3,1,sigmoid,diff_sigmoid)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.train関数とtest関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train(X,d,eps=1):\n",
    "    #forward propagation\n",
    "    y = fprops(layers,X)\n",
    "        \n",
    "    #cost function & delta\n",
    "    cost = np.sum(-d * np.log(y) - (1 - d) * np.log(1 - y))\n",
    "    delta = y - d\n",
    "    \n",
    "    #back propagation\n",
    "    bprops(layers,delta)\n",
    "\n",
    "    #update parameters\n",
    "    z = X\n",
    "    for layer in layers:\n",
    "        dW = np.dot(z.T, layer.delta)  # P.52\n",
    "        db = np.dot(np.ones(len(z)),layer.delta)  # P.52\n",
    "\n",
    "        layer.W = layer.W - eps*dW\n",
    "        layer.b = layer.b - eps*db\n",
    "\n",
    "        z = layer.fprop(z)\n",
    "        \n",
    "    #train cost\n",
    "    y = fprops(layers,X)\n",
    "    cost = np.sum(-d * np.log(y) - (1 - d) * np.log(1 - y)) # (2.8)\n",
    "    \n",
    "    return cost\n",
    "\n",
    "def test(X,d):\n",
    "    #test cost\n",
    "    y = fprops(layers,X)\n",
    "    cost = np.sum(-d * np.log(y) - (1 - d) * np.log(1 - y))\n",
    "    return cost,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6.パラメータの更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.9040565 ]\n",
      " [ 0.9355088 ]\n",
      " [ 0.03297601]\n",
      " [ 0.12862548]]\n"
     ]
    }
   ],
   "source": [
    "#epoch\n",
    "for epoch in range(100):\n",
    "    #online learning\n",
    "    train_X, train_y = shuffle(train_X, train_y)\n",
    "    train(train_X, train_y)\n",
    "    #for x,y in zip(train_X,train_y):\n",
    "    #    train(x[np.newaxis,:],y[np.newaxis,:])\n",
    "    n,pred_y = test(test_X,test_y)\n",
    "print(pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 宿題．MNISTデータセットを多層パーセプトロンで学習"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- データはmnist_x,mnist_yで与えられます\n",
    "    - mnsit_xとmnist_yをtrain_X,train_yとtest_X,test_yに分けて，モデルを学習してください\n",
    "\n",
    "ヒント\n",
    "* 出力yはone-of-k表現\n",
    "* 最終層の活性化関数はsoftmax関数，誤差関数は多クラス交差エントロピー\n",
    "* 最終層のデルタは教科書参照"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original', data_home='.')\n",
    "\n",
    "X, y = shuffle(mnist.data, mnist.target)\n",
    "X = X / 255.0\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "次のセルに解答を書いて提出してください\n",
    "- レイヤークラスなど，必要なものは全て書いてください.\n",
    "- システム側では，pred_yの結果から評価します.\n",
    "- test関数の戻り値（pred_y）は，one-of-k表現（one-hot）のままで大丈夫です."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_mldata\n",
    "mnist = fetch_mldata('MNIST original')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mnist_x, mnist_y = shuffle(mnist.data.astype(\"float32\")/255.0, mnist.target.astype(\"int32\"))\n",
    "train_x, test_x, train_y, test_y = train_test_split(mnist_x, mnist_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# one-of-k表現に変換\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "train_label_y = LabelBinarizer().fit_transform(train_y)\n",
    "test_label_y = LabelBinarizer().fit_transform(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layerクラス"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Layer:\n",
    "    def __init__(self, in_dim, out_dim, function, diff_function):\n",
    "        #Xavier\n",
    "        self.W = np.random.uniform(low=-np.sqrt(6./(in_dim+out_dim)), \n",
    "                                   high=np.sqrt(6./(in_dim+out_dim)), \n",
    "                                   size=(in_dim, out_dim)).astype('float32')\n",
    "        self.b = np.zeros(out_dim)\n",
    "        self.function = function\n",
    "        \n",
    "        self.diff_function = diff_function\n",
    "        self.u     = None\n",
    "        self.delta = None\n",
    "\n",
    "    #forward propagation\n",
    "    def fprop(self,x):\n",
    "        self.u = np.dot(x, self.W) + self.b\n",
    "        z = self.function(self.u)\n",
    "        return z\n",
    "\n",
    "    #back propagation\n",
    "    def bprop(self,delta,W):\n",
    "        self.delta = self.diff_function(self.u) * np.dot(delta, W.T)\n",
    "        return self.delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ネットワーク全体の順伝播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fprops(layers, x):\n",
    "    z = x\n",
    "    for layer in layers:\n",
    "        z = layer.fprop(z)    \n",
    "    return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ネットワーク全体の誤差逆伝播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bprops(layers, delta):\n",
    "    for i,layer in enumerate(layers[::-1]):\n",
    "        if i == 0:\n",
    "            layer.delta = delta\n",
    "        else:\n",
    "            delta = layer.bprop(delta, _W)\n",
    "        _W = layer.W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ネットワークの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "layers = [\n",
    "    Layer(784, 1000, sigmoid, diff_sigmoid),\n",
    "    Layer(1000, 1000, sigmoid, diff_sigmoid),\n",
    "    Layer(1000, 1000, sigmoid, diff_sigmoid),\n",
    "    Layer(1000, 10, softmax, diff_softmax),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train関数とtest関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(X, d, eps=0.1):\n",
    "    # forward propagation\n",
    "    y = fprops(layers, X)\n",
    "\n",
    "    # 出力層のdelta\n",
    "    delta = y - d\n",
    "    \n",
    "    # back propagation\n",
    "    bprops(layers, delta)\n",
    "\n",
    "    # update parameters\n",
    "    z = X\n",
    "    for layer in layers:\n",
    "        dW = np.dot(z.T, layer.delta) / X.shape[0] # P.52\n",
    "        db = np.dot(np.ones(len(z)), layer.delta) / X.shape[0] # P.52\n",
    "\n",
    "        layer.W = layer.W - eps*dW\n",
    "        layer.b = layer.b - eps*db\n",
    "\n",
    "        z = layer.fprop(z)\n",
    "        \n",
    "    # train cost\n",
    "    #y = fprops(layers, X)\n",
    "    #cost = -np.sum(d * np.log(y)) # (2.11)\n",
    "    #return cost\n",
    "\n",
    "def test(X, d):\n",
    "    # test cost\n",
    "    y = fprops(layers, X)\n",
    "    cost = -np.mean(d * np.log(y)) # (2.11)\n",
    "    return cost, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### パラメータの更新"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### オンライン学習\n",
    "\n",
    "`train_x`の行毎に学習する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH::   1, Validatioon Cost:: 0.037, Validation F1:: 0.888\n",
      "EPOCH::   2, Validatioon Cost:: 0.032, Validation F1:: 0.904\n",
      "EPOCH::   3, Validatioon Cost:: 0.024, Validation F1:: 0.928\n",
      "EPOCH::   4, Validatioon Cost:: 0.023, Validation F1:: 0.933\n",
      "EPOCH::   5, Validatioon Cost:: 0.020, Validation F1:: 0.941\n",
      "EPOCH::   6, Validatioon Cost:: 0.018, Validation F1:: 0.949\n",
      "EPOCH::   7, Validatioon Cost:: 0.017, Validation F1:: 0.953\n",
      "EPOCH::   8, Validatioon Cost:: 0.017, Validation F1:: 0.957\n",
      "EPOCH::   9, Validatioon Cost:: 0.015, Validation F1:: 0.962\n",
      "EPOCH::  10, Validatioon Cost:: 0.015, Validation F1:: 0.960\n"
     ]
    }
   ],
   "source": [
    "# epoch\n",
    "for epoch in range(10):\n",
    "    X, Y = shuffle(train_x, train_label_y)\n",
    "    for x, y in zip(X, Y):\n",
    "        train(x[np.newaxis,:], y[np.newaxis,:], 0.01)\n",
    "\n",
    "    if True:\n",
    "    #if ((epoch+1) % 10 == 0) or (epoch == 0):\n",
    "        cost, pred_y = test(test_x, test_label_y)\n",
    "        pred = np.argmax(pred_y, axis=1)\n",
    "        print(\"EPOCH:: {:3d}, Validatioon Cost:: {:.3f}, Validation F1:: {:.3f}\".format(epoch+1,\n",
    "                                                                                     float(cost),\n",
    "                                                                                     f1_score(test_y, pred, average=\"micro\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ミニバッチ学習\n",
    "\n",
    "教科書 3.3節"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH::   1, Validatioon Cost:: 0.230, Validation F1:: 0.135\n",
      "EPOCH::  10, Validatioon Cost:: 0.176, Validation F1:: 0.515\n",
      "EPOCH::  20, Validatioon Cost:: 0.071, Validation F1:: 0.785\n",
      "EPOCH::  30, Validatioon Cost:: 0.048, Validation F1:: 0.864\n",
      "EPOCH::  40, Validatioon Cost:: 0.041, Validation F1:: 0.883\n",
      "EPOCH::  50, Validatioon Cost:: 0.038, Validation F1:: 0.892\n",
      "EPOCH::  60, Validatioon Cost:: 0.036, Validation F1:: 0.898\n",
      "EPOCH::  70, Validatioon Cost:: 0.034, Validation F1:: 0.902\n",
      "EPOCH::  80, Validatioon Cost:: 0.033, Validation F1:: 0.905\n",
      "EPOCH::  90, Validatioon Cost:: 0.032, Validation F1:: 0.908\n",
      "EPOCH:: 100, Validatioon Cost:: 0.031, Validation F1:: 0.910\n",
      "EPOCH:: 110, Validatioon Cost:: 0.031, Validation F1:: 0.911\n",
      "EPOCH:: 120, Validatioon Cost:: 0.030, Validation F1:: 0.915\n",
      "EPOCH:: 130, Validatioon Cost:: 0.029, Validation F1:: 0.915\n",
      "EPOCH:: 140, Validatioon Cost:: 0.029, Validation F1:: 0.917\n",
      "EPOCH:: 150, Validatioon Cost:: 0.028, Validation F1:: 0.919\n",
      "EPOCH:: 160, Validatioon Cost:: 0.028, Validation F1:: 0.920\n",
      "EPOCH:: 170, Validatioon Cost:: 0.027, Validation F1:: 0.923\n",
      "EPOCH:: 180, Validatioon Cost:: 0.026, Validation F1:: 0.925\n",
      "EPOCH:: 190, Validatioon Cost:: 0.026, Validation F1:: 0.926\n",
      "EPOCH:: 200, Validatioon Cost:: 0.025, Validation F1:: 0.928\n",
      "EPOCH:: 210, Validatioon Cost:: 0.025, Validation F1:: 0.930\n",
      "EPOCH:: 220, Validatioon Cost:: 0.024, Validation F1:: 0.930\n",
      "EPOCH:: 230, Validatioon Cost:: 0.024, Validation F1:: 0.931\n",
      "EPOCH:: 240, Validatioon Cost:: 0.023, Validation F1:: 0.931\n",
      "EPOCH:: 250, Validatioon Cost:: 0.023, Validation F1:: 0.932\n",
      "EPOCH:: 260, Validatioon Cost:: 0.022, Validation F1:: 0.936\n",
      "EPOCH:: 270, Validatioon Cost:: 0.022, Validation F1:: 0.938\n",
      "EPOCH:: 280, Validatioon Cost:: 0.021, Validation F1:: 0.940\n",
      "EPOCH:: 290, Validatioon Cost:: 0.020, Validation F1:: 0.941\n",
      "EPOCH:: 300, Validatioon Cost:: 0.020, Validation F1:: 0.943\n",
      "EPOCH:: 310, Validatioon Cost:: 0.019, Validation F1:: 0.944\n",
      "EPOCH:: 320, Validatioon Cost:: 0.019, Validation F1:: 0.945\n",
      "EPOCH:: 330, Validatioon Cost:: 0.019, Validation F1:: 0.946\n",
      "EPOCH:: 340, Validatioon Cost:: 0.018, Validation F1:: 0.949\n",
      "EPOCH:: 350, Validatioon Cost:: 0.018, Validation F1:: 0.949\n",
      "EPOCH:: 360, Validatioon Cost:: 0.017, Validation F1:: 0.951\n",
      "EPOCH:: 370, Validatioon Cost:: 0.017, Validation F1:: 0.952\n",
      "EPOCH:: 380, Validatioon Cost:: 0.016, Validation F1:: 0.952\n",
      "EPOCH:: 390, Validatioon Cost:: 0.016, Validation F1:: 0.953\n",
      "EPOCH:: 400, Validatioon Cost:: 0.016, Validation F1:: 0.955\n",
      "EPOCH:: 410, Validatioon Cost:: 0.015, Validation F1:: 0.955\n",
      "EPOCH:: 420, Validatioon Cost:: 0.015, Validation F1:: 0.956\n",
      "EPOCH:: 430, Validatioon Cost:: 0.015, Validation F1:: 0.957\n",
      "EPOCH:: 440, Validatioon Cost:: 0.015, Validation F1:: 0.958\n",
      "EPOCH:: 450, Validatioon Cost:: 0.014, Validation F1:: 0.959\n",
      "EPOCH:: 460, Validatioon Cost:: 0.014, Validation F1:: 0.958\n",
      "EPOCH:: 470, Validatioon Cost:: 0.014, Validation F1:: 0.959\n",
      "EPOCH:: 480, Validatioon Cost:: 0.014, Validation F1:: 0.960\n",
      "EPOCH:: 490, Validatioon Cost:: 0.013, Validation F1:: 0.961\n",
      "EPOCH:: 500, Validatioon Cost:: 0.013, Validation F1:: 0.962\n"
     ]
    }
   ],
   "source": [
    "## Iterate\n",
    "batch_size = 100\n",
    "nbatches = train_x.shape[0] // batch_size\n",
    "\n",
    "for epoch in range(500):\n",
    "    x, y = shuffle(train_x, train_label_y)\n",
    "    for i in range(nbatches):\n",
    "        start = i * batch_size\n",
    "        end = start + batch_size\n",
    "        train(x[start:end], y[start:end], 0.01)\n",
    "\n",
    "    #if True:\n",
    "    if ((epoch+1) % 10 == 0) or (epoch == 0):\n",
    "        cost, pred_y = test(test_x, test_label_y)\n",
    "        pred = np.argmax(pred_y, axis=1)\n",
    "        print(\"EPOCH:: {:3d}, Validatioon Cost:: {:.3f}, Validation F1:: {:.3f}\".format(epoch+1,\n",
    "                                                                                     float(cost),\n",
    "                                                                                     f1_score(test_y, pred, average=\"micro\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1315    1    3    4    1    7    8    1    6    2]\n",
      " [   0 1517    8   10    3    1    2    5    2    2]\n",
      " [   2    7 1379   13    4    1    5    8    7    2]\n",
      " [   2    5   14 1308    0   21    1    8   11    6]\n",
      " [   3    6    3    2 1344    2   16    3    4   45]\n",
      " [   8    3    0   11    4 1214   10    0    5    7]\n",
      " [   7    3    3    0    2    8 1344    0    8    0]\n",
      " [   0    8    7    6   13    2    0 1399    2   14]\n",
      " [   5    9    7   17    2   10    4    3 1310   11]\n",
      " [   0    6    0   15   20    7    0    8    7 1341]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.98      0.98      0.98      1348\n",
      "          1       0.97      0.98      0.97      1550\n",
      "          2       0.97      0.97      0.97      1428\n",
      "          3       0.94      0.95      0.95      1376\n",
      "          4       0.96      0.94      0.95      1428\n",
      "          5       0.95      0.96      0.96      1262\n",
      "          6       0.97      0.98      0.97      1375\n",
      "          7       0.97      0.96      0.97      1451\n",
      "          8       0.96      0.95      0.96      1378\n",
      "          9       0.94      0.96      0.95      1404\n",
      "\n",
      "avg / total       0.96      0.96      0.96     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# テストデータを用いて予測精度を計算\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "pred = [np.argmax(v) for v in pred_y]\n",
    "print(confusion_matrix(test_y, pred))\n",
    "print(classification_report(test_y, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
